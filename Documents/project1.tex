% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)
\usepackage{hyperref}
%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
% \geometry{margin=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

%%% END Article customizations

%%% The "real" document content comes below...

\title{Project 1 Part 1 and part 2}
\author{Joshua Westbrook \& Arifur Rahman}
\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 

\begin{document}
\maketitle

\section{The maps}

The map files are available at \url{https://github.com/Joshua-Westbrook/AIproject1maps}

They are also in the folder that opens after unzipping the .zip file attached and importing it into Eclipse as an existing project.

\section{The algorithm}

The algorimths can be found in in the searches package. The UCS algorithm is fully implemented in SearchAlgo.java but uses UCS.java so it has a specific name. A* and Weighted A* overwrite the h(n) being zero in UCS with them using either the heuristic from DistanceHeuristic.java or the heuristic times the weight. UCS and A* always return the cheapest path while Weighted A* may or may not depending on the weight and the specific map with its start and goal point. In some situations such as map5j even a weight of 3.0 still has Weighted A* return the right path while other maps such as map5b return a longer path with a weight of 2.


\section{Optimizations}
One trade-off made in the algorithm is the use of a 2d array to store every node once it is added to the fringe. This allows for much quicker look up times of a node already in the fringe when checking if the new path found to that node is more optimal faster but also increases the memory requirements of the program because it will always require space to store all the nodes on the map. Due to the nodes not requiring much memory to store this is a good trade-off. In other situations the memory cost of allocating the 2d array might be worse than the time cost of iterating through the fringe, which is Java's priority queue, to retrieve the previously found hcost of reaching that node. 	

\section{Heuristics}
The Heuristic we finally used was a modified Euclidean distance . We then multiply the Euclidean distance between the currNode and goal by .25 since in a best case scenario the entire path to the goal is an highway/river with no hard to travel in which case all movements is the distance divided by 4 which is the same thing as times 0.25
The formula for the heuristic is $0.25 * \sqrt{(currNode.x - end.x)^2 + (currNode.y - end.y)^2}$.

Other attempted heuristics were the following.

1. Euclidean distance from currNode to goal. Not admissable because it is not optimistic due to not accounting for rivers in its travel cost.

2. A Heuristic that attempts to avoid cells which are hard to travel through. This ended up being useful for some maps such as map1a and map1b where it did find the optimal path but it was not optimal on the majority of the maps.

3. Chebyshev distance from current node to the goal.

4. Manhattan Distance from current node to the goal.

\section{benchmarks}
% Table generated by Excel2LaTeX from sheet 'Final Averages'
\begin{table}[htbp]
  \centering
  \caption{Results}
    \begin{tabular}{|l|l|l|l|}
	\hline
        Search method  &  Nodes & Time in MS & Cost \\
\hline
    UCS   & 12274.83673 & 69.04081633 & 113.3290976 \\
\hline
    Modified Euclidean Distance A* & 9533.163265 & 5.87755102 & 113.3290976 \\
\hline    Modified Euclidean Distance 2 weight A* & 6628.510204 & 13.3877551 & 113.9998702 \\
\hline    Modified Euclidean Distance 3 weight A* & 3700.897959 & 16.89795918 & 117.2203349 \\
\hline    Euclidean Distance A* & 1564.836735 & 6.795918367 & 122.383466 \\
\hline    Euclidean Distance 2 weight A* & 140.3265306 & 0.142857143 & 170.2938775 \\
\hline    Euclidean Distance 3 weight A* & 136.5714286 & 0.163265306 & 172.7860726 \\
\hline    Hard Cells Avoidance A* & 12177.65306 & 12.44897959 & 117.0232475 \\
\hline    Hard Cells Avoidance 2 weight A* & 11984.71429 & 25.69387755 & 118.5417895 \\
\hline    Hard Cells Avoidance 3 weight A* & 11779.40816 & 16.51020408 & 120.0317971 \\
\hline    Chebyshev A* & 9444.204082 & 9.530612245 & 120.310548 \\
\hline    Chebyshev 2 weight A* & 7708.816327 & 6.102040816 & 144.1297948 \\
\hline    Chebyshev 3 weight A* & 7261  & 6.714285714 & 153.1129255 \\
\hline    Manhattan Distance A* & 639.1632653 & 0.571428571 & 144.8362468 \\
\hline    Manhattan Distance 2 weight A* & 147.3673469 & 0.081632653 & 187.3616096 \\
\hline    Manhattan Distance 3 weight A* & 143.6734694 & 0.142857143 & 189.7389947 \\
\hline
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}%


The excel sheet that was submitted with this contains the cost for eah map with each of its individual start and end points. Alternatively they can be obtained by ruinning our program on whichever map you wish to check.



\section{Final Explanation part 1}
The results clearly show that when using an admissable heuristic while UCS and A* find the same path A* is able to do it with much less nodes expanding and a much quicker speed. Adding a weight increases the speed and decreases the nodes expanded even more but also results in a slightly higher cost found on average. This makes it clear that using A* when you have an admissable heuristic is always better than using UCS and UCS should only be used in situations where an admissable heuristic isn't available. It also shows that weighted A* can be used to increase the speed of the algorithm and reduce the nodes expanded but that will also reduce the ability to get an optimal path. Many maps, such as 5a and 1j, see a pure increase in performance when using a weight of 2 which says that it is often worth using at least a small weight to increase your performance because the path found is very close to optimal at least on the maps we have. This is also shown by the average cost of A* with a weight of 2 only being 0.76 higher than the average optimal path from UCS/A* when using an admissable heuristic which is less than the cost of moving between two normal nodes. Meanwhile the average cost for A* with a weight of 3 is around 4 higher than the optimal path which makes it very clear that using larger weights will almost always cause a noticable increase in the cost of the found path. Although the inadmissable heuristics definitely did not come close to finding optimal paths there were clearly occassions where they would be useful. The unmodified Euclidean distance looked at under 150 nodes on average when weighted and was also noticable faster on the system which was used for benchmarking. This much faster and much less nodes look at is also shown by the Manhattan Distance which looks at much less nodes compared to UCS and an admissable A* even when not weighted. The shown results match what is expected. A* requires an admissable heuristic to a path of the same cost as UCS while always decreasing the number  of nodes looked at compared to UCS. Adding a weight to A* always decreases the number of nodes looked at and the increase is bigger with bigger weights but this also icnreasese the cost of the found path. The one oddity is that the Manhattan Distance with a weight of 2 had an average time of roughly 0.08 milliseconds while the Manhattan Distance with a weight 3 had a time of 0.14 MS. However that is easily explainable by the machine using less resources for some runs compared to others and the difference being from how many runs took 0 milliseconds versus 1 millisecond according to Java. This suggests that it is likely due to Java's own rounding combined with not being able to be certain the amount of resources dedicated was the cause rather than any issue with the algorithm since using Manhattan distance and a weight of 3 did expand less nodes but also find a higher cost path compared to using a weight of 2.

\section{Info about part 2}
We did not have time to implement Integrated A*. We did implement Sequential A*
\pagebreak
\section{Sequential A* benchmark averages}
% Table generated by Excel2LaTeX from sheet 'Final Averages'
\begin{table}[htbp]
  \centering
  \caption{Results}
    \begin{tabular}{|l|l|l|l|}
	\hline
        Search method  &  Nodes & Time in MS & Cost \\
\hline
    UCS   & 12274.83673 & 69.04081633 & 113.3290976 \\
\hline
    Modified Euclidean Distance A* & 9533.163265 & 5.87755102 & 113.3290976 \\
\hline    Modified Euclidean Distance 2 weight A* & 6628.510204 & 13.3877551 & 113.9998702 \\
\hline    Modified Euclidean Distance 3 weight A* & 3700.897959 & 16.89795918 & 117.2203349 \\
\hline    Euclidean Distance A* & 1564.836735 & 6.795918367 & 122.383466 \\
\hline    Euclidean Distance 2 weight A* & 140.3265306 & 0.142857143 & 170.2938775 \\
\hline    Euclidean Distance 3 weight A* & 136.5714286 & 0.163265306 & 172.7860726 \\
\hline    Hard Cells Avoidance A* & 12177.65306 & 12.44897959 & 117.0232475 \\
\hline    Hard Cells Avoidance 2 weight A* & 11984.71429 & 25.69387755 & 118.5417895 \\
\hline    Hard Cells Avoidance 3 weight A* & 11779.40816 & 16.51020408 & 120.0317971 \\
\hline    Chebyshev A* & 9444.204082 & 9.530612245 & 120.310548 \\
\hline    Chebyshev 2 weight A* & 7708.816327 & 6.102040816 & 144.1297948 \\
\hline    Chebyshev 3 weight A* & 7261  & 6.714285714 & 153.1129255 \\
\hline    Manhattan Distance A* & 639.1632653 & 0.571428571 & 144.8362468 \\
\hline    Manhattan Distance 2 weight A* & 147.3673469 & 0.081632653 & 187.3616096 \\
\hline    Manhattan Distance 3 weight A* & 143.6734694 & 0.142857143 & 189.7389947 \\
\hline 1.25 weight Sequential A* & 8907.55102 & 37.12244898 & 113.3745638 \\
  \hline  2 weight Sequential A* & 6968.714286 & 55.46938776   & 114.0504389\\
\hline
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}%

The results show that sequential A* with the Modified Euclidean Distance as an anchor uses less nodes than the modified Euclidean Distance while finding a slightly more expensive path but one that is only roughly 0.05 more expensive with a weight of 1.25. The weight of 2 performed worse than using a weight of 2 on just the modified Euclidean distance however. It appears for our maps that Sequential A* with a weight of 1.25 performs the best in terms of nodes expanded when you do not need an optimal path.

\section{Implementation}
The implementation of sequential A* is efficient because the hashmap used to store the map of the nodes provides constant time retrieval with a good hash. 

The memory effiency is also showed by the reduced amount of nodes stored compared to A*. 

However due to the nature of Sequential search it does use more computation time than UCS, A*, and Weighted A*

This shows that Sequential source is most useful in times of low memory availability.

\section{proof i}
There was no time to do this

\section{proof j}
There was no time to do this
\end{document}
